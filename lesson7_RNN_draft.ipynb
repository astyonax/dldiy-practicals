{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our first RNN\n",
    "\n",
    "The goal of this lesson is to introduce the ideas behind Recurrent Neural Networks.\n",
    "\n",
    "A very good starting point: [Karpathy's blog](http://karpathy.github.io/2015/05/21/rnn-effectiveness)\n",
    "\n",
    "and the associated [code](https://github.com/karpathy/char-rnn) \n",
    "\n",
    "Fortunately, the code is not in pytorch, so that you can now 'translate it'!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch_utils import ScaledEmbedding\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_utils; \n",
    "from torch_utils import gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to download the collected works of Nietzsche to use as our data for this class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_folder = '/home/lelarge/courses/data/nietzsche/'\n",
    "data_nie = data_folder+'nietzsche.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%mkdir -p $data_folder\n",
    "#!wget -O $data_nie 'https://s3.amazonaws.com/text-datasets/nietzsche.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 600893\n"
     ]
    }
   ],
   "source": [
    "text = open(data_nie).read()\n",
    "print('corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 85\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)+1\n",
    "print('total chars:', vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chars.insert(0, \"\\0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n !\"\\'(),-.0123456789:;=?ABCDEFGHIJKLMNOPQRSTUVWXYZ[]_abcdefghijklmnopqrstuvwxy'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(chars[1:-6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map from chars to indices and back again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "idx will be the data we use from now own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = [char_indices[c] for c in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[40, 42, 29, 30, 25, 27, 29, 1, 1, 1]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PREFACE\\n\\n\\nSUPPOSING that Truth is a woman--what then? Is the'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(indices_char[i] for i in idx[:60])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Char"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to learn the 4-th character from the 3 first ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cs=3\n",
    "c1_dat = [idx[i] for i in range(0, len(idx)-1-cs, cs)]\n",
    "c2_dat = [idx[i+1] for i in range(0, len(idx)-1-cs, cs)]\n",
    "c3_dat = [idx[i+2] for i in range(0, len(idx)-1-cs, cs)]\n",
    "c4_dat = [idx[i+3] for i in range(0, len(idx)-1-cs, cs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x1 = np.stack(c1_dat[:-2])\n",
    "x2 = np.stack(c2_dat[:-2])\n",
    "x3 = np.stack(c3_dat[:-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = np.stack(c4_dat[:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([40, 30, 29,  1]), array([42, 25,  1, 43]), array([29, 27,  1, 45]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1[:4], x2[:4], x3[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([30, 29,  1, 40])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200295,), (200295,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Char-RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am using the architecture described in [Lesson 6 of fast.ai course](http://wiki.fast.ai/index.php/Lesson_6_Notes#Recurrent_Neural_Network_.28RNN.29:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, embedding_dim=42, vocab_size = 1, hidden_dim =256):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self._embedding_dim = embedding_dim\n",
    "        self._vocab_size = vocab_size\n",
    "        self._hidden_dim = hidden_dim\n",
    "        \n",
    "        self.embeddings = ScaledEmbedding(vocab_size, embedding_dim)\n",
    "        self.i2h = nn.Linear(embedding_dim, hidden_dim)\n",
    "        self.h2h = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.h2o = nn.Linear(hidden_dim, vocab_size)\n",
    "            \n",
    "    def forward(self, c1, c2, c3):\n",
    "        c1_embedding = self.embeddings(c1)\n",
    "        c2_embedding = self.embeddings(c2)\n",
    "        c3_embedding = self.embeddings(c3)\n",
    "        c1_r = F.relu(self.i2h(c1_embedding))\n",
    "        c2_r = F.relu(self.i2h(c2_embedding))\n",
    "        c3_r = F.relu(self.i2h(c3_embedding))\n",
    "        h2 = F.tanh(self.h2h(c1_r))\n",
    "        h3 = F.tanh(self.h2h(h2+c2_r))\n",
    "        output = self.h2o(h3+c3_r)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rnn = RNN(vocab_size=vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "in1 = Variable(gpu(torch.from_numpy(np.array([idx[0]]).astype(np.int64))))\n",
    "in2 = Variable(gpu(torch.from_numpy(np.array([idx[1]]).astype(np.int64))))\n",
    "in3 = Variable(gpu(torch.from_numpy(np.array([idx[2]]).astype(np.int64))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out = rnn(in1,in2,in3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "\n",
       "Columns 0 to 9 \n",
       "-0.0245 -0.0220 -0.1027 -0.1586 -0.0403  0.0261  0.0605 -0.0767 -0.0182  0.0008\n",
       "\n",
       "Columns 10 to 19 \n",
       " 0.0616  0.0658  0.0591 -0.0109 -0.0945 -0.0509 -0.1279 -0.1257  0.0811 -0.0466\n",
       "\n",
       "Columns 20 to 29 \n",
       " 0.0288  0.0015 -0.0207  0.0747 -0.0856  0.0547 -0.0007  0.0803  0.0031  0.0207\n",
       "\n",
       "Columns 30 to 39 \n",
       " 0.0143 -0.0338 -0.0827 -0.1020  0.0759  0.0703 -0.0587 -0.1110 -0.0033 -0.0895\n",
       "\n",
       "Columns 40 to 49 \n",
       " 0.0252  0.1196  0.0655 -0.0822 -0.0140 -0.0154 -0.0512 -0.0382  0.1218  0.0110\n",
       "\n",
       "Columns 50 to 59 \n",
       "-0.0996 -0.0840  0.0190  0.0546 -0.1337  0.0081 -0.0951 -0.1081  0.0785  0.0750\n",
       "\n",
       "Columns 60 to 69 \n",
       "-0.0137  0.0650  0.0895  0.0697 -0.1337  0.0203  0.0800 -0.0611  0.0033 -0.0344\n",
       "\n",
       "Columns 70 to 79 \n",
       "-0.0189  0.0474 -0.0107  0.0112 -0.0555  0.0359  0.0826  0.0071  0.0435 -0.0477\n",
       "\n",
       "Columns 80 to 84 \n",
       " 0.0649 -0.0492  0.0240 -0.0188  0.0309\n",
       "[torch.FloatTensor of size 1x85]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with a batch of size 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "in1 = Variable(gpu(torch.from_numpy(np.array([x1[:2]]).astype(np.int64))).squeeze())\n",
    "in2 = Variable(gpu(torch.from_numpy(np.array([x2[:2]]).astype(np.int64))).squeeze())\n",
    "in3 = Variable(gpu(torch.from_numpy(np.array([x3[:2]]).astype(np.int64))).squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 40\n",
       " 30\n",
       "[torch.LongTensor of size 2]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out = rnn(in1,in2,in3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "\n",
       "Columns 0 to 9 \n",
       "-0.0245 -0.0220 -0.1027 -0.1586 -0.0403  0.0261  0.0605 -0.0767 -0.0182  0.0008\n",
       "-0.0194 -0.0330 -0.1015 -0.1556 -0.0453  0.0255  0.0437 -0.0738 -0.0246 -0.0196\n",
       "\n",
       "Columns 10 to 19 \n",
       " 0.0616  0.0658  0.0591 -0.0109 -0.0945 -0.0509 -0.1279 -0.1257  0.0811 -0.0466\n",
       " 0.0476  0.0624  0.0609 -0.0044 -0.0862 -0.0388 -0.1554 -0.1366  0.0714 -0.0449\n",
       "\n",
       "Columns 20 to 29 \n",
       " 0.0288  0.0015 -0.0207  0.0747 -0.0856  0.0547 -0.0007  0.0803  0.0031  0.0207\n",
       " 0.0176 -0.0007 -0.0208  0.0679 -0.0802  0.0497 -0.0164  0.0831 -0.0060  0.0317\n",
       "\n",
       "Columns 30 to 39 \n",
       " 0.0143 -0.0338 -0.0827 -0.1020  0.0759  0.0703 -0.0587 -0.1110 -0.0033 -0.0895\n",
       " 0.0122 -0.0442 -0.0711 -0.0978  0.0792  0.0780 -0.0497 -0.1086  0.0113 -0.0946\n",
       "\n",
       "Columns 40 to 49 \n",
       " 0.0252  0.1196  0.0655 -0.0822 -0.0140 -0.0154 -0.0512 -0.0382  0.1218  0.0110\n",
       " 0.0166  0.1086  0.0617 -0.0817 -0.0218 -0.0177 -0.0480 -0.0479  0.1060  0.0066\n",
       "\n",
       "Columns 50 to 59 \n",
       "-0.0996 -0.0840  0.0190  0.0546 -0.1337  0.0081 -0.0951 -0.1081  0.0785  0.0750\n",
       "-0.0868 -0.0849  0.0181  0.0593 -0.1374  0.0090 -0.0672 -0.1177  0.0644  0.0580\n",
       "\n",
       "Columns 60 to 69 \n",
       "-0.0137  0.0650  0.0895  0.0697 -0.1337  0.0203  0.0800 -0.0611  0.0033 -0.0344\n",
       "-0.0110  0.0710  0.0800  0.0728 -0.1383  0.0211  0.0814 -0.0678  0.0083 -0.0365\n",
       "\n",
       "Columns 70 to 79 \n",
       "-0.0189  0.0474 -0.0107  0.0112 -0.0555  0.0359  0.0826  0.0071  0.0435 -0.0477\n",
       "-0.0219  0.0295 -0.0219  0.0108 -0.0663  0.0286  0.0853  0.0084  0.0447 -0.0169\n",
       "\n",
       "Columns 80 to 84 \n",
       " 0.0649 -0.0492  0.0240 -0.0188  0.0309\n",
       " 0.0518 -0.0673  0.0137 -0.0075  0.0296\n",
       "[torch.FloatTensor of size 2x85]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rnn_loss = nn.CrossEntropyLoss()\n",
    "lr = 0.000001\n",
    "rnn_optimizer = torch.optim.Adam(rnn.parameters(),lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def char2Var(ch):\n",
    "    return Variable(gpu(torch.from_numpy(np.array([ch]).astype(np.int64))).squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_gen(c1,c2,c3,c4,batch_size=64,shuffle=True):\n",
    "    if shuffle:\n",
    "        index = np.random.permutation(c1.shape[0])\n",
    "        c1 = c1[index]\n",
    "        c2 = c2[index]\n",
    "        c3 = c3[index]\n",
    "        c4 = c4[index]\n",
    "    for idx in range(0,c1.shape[0],batch_size):\n",
    "        yield(c1[idx:idx+batch_size],c2[idx:idx+batch_size], c3[idx:idx+batch_size], c4[idx:idx+batch_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(c1,c2,c3,c4,model=rnn,epochs=1,train=True):\n",
    "    if train:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "        \n",
    "    for epoch in range(epochs):\n",
    "        batches = data_gen(c1,c2,c3,c4)\n",
    "        running_loss = 0.0\n",
    "        for ch1,ch2,ch3,ch4 in batches:\n",
    "            in1 = char2Var(ch1)#Variable(gpu(torch.from_numpy(np.array([ch1]).astype(np.int64))).squeeze())\n",
    "            in2 = char2Var(ch2)#Variable(gpu(torch.from_numpy(np.array([ch2]).astype(np.int64))).squeeze())\n",
    "            in3 = char2Var(ch3)#Variable(gpu(torch.from_numpy(np.array([ch3]).astype(np.int64))).squeeze())\n",
    "            ou4 = char2Var(ch4)#Variable(gpu(torch.from_numpy(np.array([ch4]).astype(np.int64))).squeeze())\n",
    "            \n",
    "            out = rnn(in1,in2,in3)\n",
    "            loss = rnn_loss(out,ou4)\n",
    "            rnn_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            rnn_optimizer.step()\n",
    "            \n",
    "            running_loss += loss.data[0]\n",
    "            \n",
    "        epoch_loss = running_loss / c1.shape[0]\n",
    "        print('Loss: {:.4f}'.format(epoch_loss))            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.1063\n",
      "CPU times: user 36 ms, sys: 0 ns, total: 36 ms\n",
      "Wall time: 21.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_model(x1[:4], x2[:4], x3[:4], y[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0681\n",
      "CPU times: user 1min 17s, sys: 1.84 s, total: 1min 19s\n",
      "Wall time: 27.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_model(x1, x2, x3, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "rnn_optimizer = torch.optim.Adam(rnn.parameters(),lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0395\n",
      "CPU times: user 1min 24s, sys: 2.02 s, total: 1min 26s\n",
      "Wall time: 32.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_model(x1, x2, x3, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_next(inp):\n",
    "    idxs = [char_indices[c] for c in inp]\n",
    "    arrs = [char2Var(i)[np.newaxis] for i in idxs]\n",
    "    out = rnn(arrs[0], arrs[1], arrs[2])\n",
    "    i = np.argmax(out.data.numpy())\n",
    "    return chars[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next(' th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next(' an')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN with pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now use the Recurrent layers of pytorch. The documentation is [here](http://pytorch.org/docs/master/nn.html#rnn)\n",
    "\n",
    "To understand it, we will use a very simple example taken from PyTorchZeroToAll [tutorials](https://github.com/hunkim/PyTorchZeroToAll/blob/master/12_1_rnn_basics.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs size torch.Size([5, 4])\n",
      "one input size torch.Size([1, 1, 4]) out size torch.Size([1, 1, 2]) hidden size torch.Size([1, 1, 2])\n",
      "one input size torch.Size([1, 1, 4]) out size torch.Size([1, 1, 2]) hidden size torch.Size([1, 1, 2])\n",
      "one input size torch.Size([1, 1, 4]) out size torch.Size([1, 1, 2]) hidden size torch.Size([1, 1, 2])\n",
      "one input size torch.Size([1, 1, 4]) out size torch.Size([1, 1, 2]) hidden size torch.Size([1, 1, 2])\n",
      "one input size torch.Size([1, 1, 4]) out size torch.Size([1, 1, 2]) hidden size torch.Size([1, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# One hot encoding for each char in 'hello'\n",
    "h = [1, 0, 0, 0]\n",
    "e = [0, 1, 0, 0]\n",
    "l = [0, 0, 1, 0]\n",
    "o = [0, 0, 0, 1]\n",
    "\n",
    "# One cell RNN input_dim (4) -> output_dim (2). sequence: 5\n",
    "cell = nn.RNN(input_size=4, hidden_size=2, batch_first=True)\n",
    "\n",
    "# (batch, num_layers * num_directions, hidden_size) for batch_first=True\n",
    "hidden = (Variable(torch.randn(1, 1, 2)))\n",
    "\n",
    "# Propagate input through RNN\n",
    "# Input: (batch, seq_len, input_size) when batch_first=True\n",
    "inputs = Variable(torch.Tensor([h, e, l, l, o]))\n",
    "print('inputs size', inputs.size())\n",
    "for one in inputs:\n",
    "    one = one.view(1, 1, -1)\n",
    "    # Input: (batch, seq_len, input_size) when batch_first=True\n",
    "    out, hidden = cell(one, hidden)\n",
    "    print(\"one input size\", one.size(), \"out size\", out.size(), 'hidden size', hidden.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence input size torch.Size([1, 5, 4]) out size torch.Size([1, 5, 2]) hidden size torch.Size([1, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "hidden = (Variable(torch.randn(1, 1, 2)))\n",
    "# We can do the whole at once\n",
    "# Propagate input through RNN\n",
    "# Input: (batch, seq_len, input_size) when batch_first=True\n",
    "inputs = inputs.view(1, 5, -1)\n",
    "out, hidden = cell(inputs, hidden)\n",
    "print(\"sequence input size\", inputs.size(), \"out size\", out.size(), 'hidden size', hidden.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch input size torch.Size([3, 5, 4]) out size torch.Size([3, 5, 2]) hidden size torch.Size([1, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "# Strange batch number for hidden can be arbitrary?\n",
    "hidden = (Variable(torch.randn(3, 1, 2)))\n",
    "\n",
    "# One cell RNN input_dim (4) -> output_dim (2). sequence: 5, batch 3\n",
    "# 3 batches 'hello', 'eolll', 'lleel'\n",
    "inputs = Variable(torch.Tensor([[h, e, l, l, o],\n",
    "                                [e, o, l, l, l],\n",
    "                                [l, l, e, e, l]]))\n",
    "\n",
    "# Propagate input through RNN\n",
    "# Input: (batch, seq_len, input_size) when batch_first=True\n",
    "# B x S x I\n",
    "out, hidden = cell(inputs, hidden)\n",
    "print(\"batch input size\", inputs.size(), \"out size\", out.size(), 'hidden size', hidden.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be a bug: the hidden state has size (num_layers * num_directions, batch, hidden_size)?\n",
    "\n",
    "We are now ready to build our new RNN with an arbitrary number of characters in input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class new_RNN(nn.Module):\n",
    "    def __init__(self, embedding_dim=42, vocab_size = 1, hidden_dim =256):\n",
    "        super(new_RNN, self).__init__()\n",
    "        \n",
    "        self._embedding_dim = embedding_dim\n",
    "        self._vocab_size = vocab_size\n",
    "        self._hidden_dim = hidden_dim\n",
    "               \n",
    "        self.embeddings = ScaledEmbedding(vocab_size, embedding_dim)\n",
    "        self.cell = nn.RNN(input_size=embedding_dim, hidden_size=hidden_dim, batch_first=True)\n",
    "        self.h2o = nn.Linear(hidden_dim, vocab_size)\n",
    "        \n",
    "    def forward(self, c):\n",
    "        #print(c.size(1))\n",
    "        hidden = Variable(torch.zeros(c.size(0),1,self._hidden_dim))\n",
    "        for i in range(c.size(1)):\n",
    "            #print(self.embeddings(c[:,i]).size())\n",
    "            #print(self.embeddings(c[:,i]).unsqueeze(1).size(),hidden.size())\n",
    "            outp,hidden = self.cell(self.embeddings(c[:,i]).unsqueeze(1),hidden)\n",
    "            #print(i, outp.size())\n",
    "        output = self.h2o(outp)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_rnn = new_RNN(vocab_size=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp = char2Var(idx[:8]).view(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "   40    42    29    30    25    27    29     1\n",
       "[torch.LongTensor of size 1x8]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 40\n",
       "[torch.LongTensor of size 1]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb = ScaledEmbedding(vocab_size, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 30])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb(inp[:,0]).unsqueeze(1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out = new_rnn(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 85])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cs=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_in_dat = [[idx[i+n] for i in range(0, len(idx)-1-cs, cs)]\n",
    "            for n in range(cs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 75111)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(c_in_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_out_dat = [idx[i+cs] for i in range(0, len(idx)-1-cs, cs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xs = [np.stack(c[:-2]) for c in c_in_dat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, (75109,))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xs), xs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = np.stack(c_out_dat[:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75109,)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([40,  1, 33,  2, 72]),\n",
       " array([42,  1, 38, 44,  2]),\n",
       " array([29, 43, 31, 71, 54]),\n",
       " array([30, 45,  2, 74,  2]),\n",
       " array([25, 40, 73, 73, 76]),\n",
       " array([27, 40, 61, 61, 68]),\n",
       " array([29, 39, 54,  2, 66]),\n",
       " array([ 1, 43, 73, 62, 54])]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[xs[n][:5] for n in range(cs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, 33,  2, 72, 67])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[40, 42, 29, 30, 25, 27, 29, 1, 1, 1, 43, 45, 40, 40, 39, 43]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx[:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp = char2Var([xs[n][:2] for n in range(cs)]).permute(1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "   40    42    29    30    25    27    29     1\n",
       "    1     1    43    45    40    40    39    43\n",
       "[torch.LongTensor of size 2x8]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out = new_rnn(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_data_gen(ch,y,batch_size=64,shuffle=True):\n",
    "    if shuffle:\n",
    "        index = np.random.permutation(ch.shape[0])\n",
    "        ch = ch[index,:]\n",
    "        y = y[index]\n",
    "    for idx in range(0,ch.shape[0],batch_size):\n",
    "        yield(ch[idx:idx+batch_size,:], y[idx:idx+batch_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_train_model(ch,y,model=new_rnn,epochs=1,train=True):\n",
    "    if train:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "        \n",
    "    for epoch in range(epochs):\n",
    "        batches = new_data_gen(ch,y)\n",
    "        running_loss = 0.0\n",
    "        for ch,y in batches:\n",
    "            inp = char2Var(ch)\n",
    "            o = char2Var(y)\n",
    "            \n",
    "            out = new_rnn(inp)\n",
    "            #print(out.squeeze().size(), o.size())\n",
    "            loss = new_rnn_loss(out.squeeze(),o)\n",
    "            new_rnn_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            new_rnn_optimizer.step()\n",
    "            \n",
    "            running_loss += loss.data[0]\n",
    "            \n",
    "        epoch_loss = running_loss / ch.shape[0]\n",
    "        print('Loss: {:.4f}'.format(epoch_loss))            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_rnn_loss = nn.CrossEntropyLoss()\n",
    "lr = 0.000001\n",
    "new_rnn_optimizer = torch.optim.Adam(new_rnn.parameters(),lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.2359\n",
      "CPU times: user 24 ms, sys: 8 ms, total: 32 ms\n",
      "Wall time: 15 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "new_train_model(np.transpose([xs[n][:2] for n in range(cs)]),y[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 140.1240\n",
      "CPU times: user 1min 21s, sys: 1.75 s, total: 1min 23s\n",
      "Wall time: 28.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "new_train_model(np.transpose([xs[n][:] for n in range(cs)]),y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "new_rnn_optimizer = torch.optim.Adam(new_rnn.parameters(),lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 109.0212\n",
      "CPU times: user 1min 25s, sys: 1.68 s, total: 1min 27s\n",
      "Wall time: 30.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "new_train_model(np.transpose([xs[n][:] for n in range(cs)]),y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_get_next(inp):\n",
    "    idxs = [char_indices[c] for c in inp]\n",
    "    #print(idxs)\n",
    "    #arrs = [char2Var(i)[np.newaxis] for i in idxs]\n",
    "    arrs = char2Var(idxs).unsqueeze(0)\n",
    "    #print(arrs)\n",
    "    out = new_rnn(arrs)\n",
    "    i = np.argmax(out.data.numpy())\n",
    "    return chars[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_get_next('for thos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_get_next('part of ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exercise\n",
    "\n",
    "As stated during the course, this code is very preliminary and does not run on GPU. Fix it!\n",
    "\n",
    "Also instead of RNN, use [GRU](http://pytorch.org/docs/master/nn.html#torch.nn.GRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
